{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nimport re\n","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/first-gop-debate-twitter-sentiment/Sentiment.csv')\n# Keeping only the neccessary columns\ndata = data[['text','sentiment']]","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"                                                    text sentiment\n0      RT @NancyLeeGrahn: How did everyone feel about...   Neutral\n1      RT @ScottWalker: Didn't catch the full #GOPdeb...  Positive\n2      RT @TJMShow: No mention of Tamir Rice and the ...   Neutral\n3      RT @RobGeorge: That Carly Fiorina is trending ...  Positive\n4      RT @DanScavino: #GOPDebate w/ @realDonaldTrump...  Positive\n...                                                  ...       ...\n13866  RT @cappy_yarbrough: Love to see men who will ...  Negative\n13867  RT @georgehenryw: Who thought Huckabee exceede...  Positive\n13868  RT @Lrihendry: #TedCruz As President, I will a...  Positive\n13869  RT @JRehling: #GOPDebate Donald Trump says tha...  Negative\n13870  RT @Lrihendry: #TedCruz headed into the Presid...  Positive\n\n[13871 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13866</th>\n      <td>RT @cappy_yarbrough: Love to see men who will ...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>13867</th>\n      <td>RT @georgehenryw: Who thought Huckabee exceede...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>13868</th>\n      <td>RT @Lrihendry: #TedCruz As President, I will a...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>13869</th>\n      <td>RT @JRehling: #GOPDebate Donald Trump says tha...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>13870</th>\n      <td>RT @Lrihendry: #TedCruz headed into the Presid...</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>13871 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data[data.sentiment != \"Neutral\"] # removing neutral values as of now\ndata['text'] = data['text'].apply(lambda x: x.lower())\ndata['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n\nprint(\"Positive Sentiment Size: \" ,data[ data['sentiment'] == 'Positive'].size)\nprint(\"Negative Sentiment Size: \" ,data[ data['sentiment'] == 'Negative'].size)\n\n\nfor idx,row in data.iterrows():\n    row[0] = row[0].replace('rt',' ')  # replace the RT token in the tweets\n    \nmax_fatures = 2000   # using maximum features as 2000\ntokenizer = Tokenizer(num_words=max_fatures, split=' ')\ntokenizer.fit_on_texts(data['text'].values)\nX = tokenizer.texts_to_sequences(data['text'].values)\nX = pad_sequences(X)","execution_count":42,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"},{"output_type":"stream","text":"Positive Sentiment Size:  4472\nNegative Sentiment Size:  16986\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"(10729, 28)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Building the LSTM network"},{"metadata":{},"cell_type":"markdown","source":"Using softmax as activation function since our Network is using categorical crossentropy, and softmax is just the right activation method for that."},{"metadata":{"trusted":true},"cell_type":"code","source":"embed_dim = 128\nlstm_out = 196\n\nmodel = Sequential()\nmodel.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\nmodel.add(SpatialDropout1D(0.4))\nmodel.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\nprint(model.summary())","execution_count":44,"outputs":[{"output_type":"stream","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, 28, 128)           256000    \n_________________________________________________________________\nspatial_dropout1d_3 (Spatial (None, 28, 128)           0         \n_________________________________________________________________\nlstm_3 (LSTM)                (None, 196)               254800    \n_________________________________________________________________\ndense_3 (Dense)              (None, 2)                 394       \n=================================================================\nTotal params: 511,194\nTrainable params: 511,194\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = pd.get_dummies(data['sentiment']).values\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","execution_count":45,"outputs":[{"output_type":"stream","text":"(7188, 28) (7188, 2)\n(3541, 28) (3541, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nmodel.fit(X_train, Y_train, epochs = 10, batch_size=batch_size, verbose = 2)","execution_count":46,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n225/225 - 18s - loss: 0.4319 - accuracy: 0.8168\nEpoch 2/10\n225/225 - 17s - loss: 0.3191 - accuracy: 0.8649\nEpoch 3/10\n225/225 - 18s - loss: 0.2744 - accuracy: 0.8870\nEpoch 4/10\n225/225 - 17s - loss: 0.2463 - accuracy: 0.8986\nEpoch 5/10\n225/225 - 17s - loss: 0.2193 - accuracy: 0.9107\nEpoch 6/10\n225/225 - 18s - loss: 0.1974 - accuracy: 0.9190\nEpoch 7/10\n225/225 - 18s - loss: 0.1753 - accuracy: 0.9285\nEpoch 8/10\n225/225 - 18s - loss: 0.1586 - accuracy: 0.9368\nEpoch 9/10\n225/225 - 18s - loss: 0.1458 - accuracy: 0.9424\nEpoch 10/10\n225/225 - 18s - loss: 0.1310 - accuracy: 0.9452\n","name":"stdout"},{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f51343669d0>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Creating the validation dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_size = 1500\n\nX_validate = X_test[-validation_size:]\nY_validate = Y_test[-validation_size:]\nX_test = X_test[:-validation_size]\nY_test = Y_test[:-validation_size]\nscore,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\nprint(\"score: %.2f\" % (score))\nprint(\"acc: %.2f\" % (acc))","execution_count":47,"outputs":[{"output_type":"stream","text":"64/64 - 1s - loss: 0.5665 - accuracy: 0.8373\nscore: 0.57\nacc: 0.84\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"twt = ['Wouldnt it be better if I was non existent']\n#vectorizing the tweet by the pre-fitted tokenizer instance\ntwt = tokenizer.texts_to_sequences(twt)\n#padding the tweet to have exactly the same shape as `embedding_2` input\ntwt = pad_sequences(twt, maxlen=28, dtype='int32', value=0)\nprint(twt)\nsentiment = model.predict(twt,batch_size=1,verbose = 2)[0]\nif(np.argmax(sentiment) == 0):\n    print(\"negative\")\nelif (np.argmax(sentiment) == 1):\n    print(\"positive\")","execution_count":51,"outputs":[{"output_type":"stream","text":"[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   0 837  13  34 215  56   9  21]]\n1/1 - 0s\nnegative\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}